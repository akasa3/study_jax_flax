{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "https://flax.readthedocs.io/en/latest/getting_started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flax Linen API を使用してシンプルなCNNを構築し，MNISTデータセットを学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-7643832d-1e3a-0941-db93-db6078bd9220)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  4 20:12:17 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 30%   38C    P8    26W / 350W |     36MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.config.experimental.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    '''A simple CNN model.'''\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1)) # flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define loss\n",
    "`optax.softmax_cross_entropy()` の入力である `logit`, `labels` の形状は共に `[batch, num_classes]` の必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(*, logits, labels):\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Metric computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(*, logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
    "  ds_builder = tfds.builder('mnist')\n",
    "  ds_builder.download_and_prepare()\n",
    "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "  return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create train state\n",
    "Flaxの一般的なパターンは，ステップ番号，パラメータ，オプティマイザの状態などを含めた学習状態全体を表す1つのデータクラスを作成することである．また，このデータクラスにオプティマイザやモデルを追加することで，`train_step()`のような関数に渡す引数が1つで済むという利点もある．これはよくあるパターンであるため，`flax.training.train_state.TrainState` というクラスを提供しており，ほとんど基本的なユースケースに対応している．追跡データを追加する場合は，このクラスをサブクラス化することで可能である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    cnn = CNN()\n",
    "    params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=cnn.apply, params=params, tx=tx\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training step\n",
    "- `Module.apply` を使用して，パラメータと入力画像のバッチを指定し，NNを評価する\n",
    "- `cross_entropy_loss` を計算する\n",
    "- `jax.value_and_grad` を使用して損失関数とその勾配を評価する\n",
    "- モデルのパラメータを更新するために，オプティマイザに勾配の `pytree` を適用する\n",
    "- `compute_metrics` を用いてメトリクスを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  def loss_fn(params):\n",
    "    logits = CNN().apply({'params': params}, batch['image'])\n",
    "    loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
    "    return loss, logits\n",
    "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "  (_, logits), grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "  return state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "    logits = CNN().apply({'params': params}, batch['image'])\n",
    "    return compute_metrics(logits=logits, labels=batch['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train function\n",
    "- 疑似乱数生成鍵をパラメータとする `jax.random.permutation` を使用して，各エポックの前に学習データーをシャッフルする\n",
    "- 各バッチに対して最適化ステップを実行する\n",
    "- `jax.device_get` でデバイスからトレーニングメトリクスを取得し，エポックないの各バッチ間の平均を計算する\n",
    "- パラメータを更新したオプティマイザを，トレーニングの損失と精度のメトリクスと共に返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    '''Train for a single epoch.'''\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    batch_metrics = []\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "\n",
    "    print(f\"train epoch: {epoch}, loss: {epoch_metrics_np['loss']:.4f}, accuracy: {100 * epoch_metrics_np['accuracy']:.2f}\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Eval function\n",
    "- `jax.device_get` でデバイスから評価指標を取得する\n",
    "- JAX pytree に格納されているメトリクスデータをコピーする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(params, test_ds):\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Seed randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Initialize train state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(init_rng, learning_rate, momentum)\n",
    "del init_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.1347, accuracy: 95.89\n",
      "test epoch: 1, loss: 0.12, accuracy: 96.17\n",
      "train epoch: 2, loss: 0.0489, accuracy: 98.57\n",
      "test epoch: 2, loss: 0.04, accuracy: 98.81\n",
      "train epoch: 3, loss: 0.0347, accuracy: 98.95\n",
      "test epoch: 3, loss: 0.04, accuracy: 98.80\n",
      "train epoch: 4, loss: 0.0292, accuracy: 99.06\n",
      "test epoch: 4, loss: 0.04, accuracy: 98.89\n",
      "train epoch: 5, loss: 0.0217, accuracy: 99.34\n",
      "test epoch: 5, loss: 0.04, accuracy: 98.78\n",
      "train epoch: 6, loss: 0.0172, accuracy: 99.45\n",
      "test epoch: 6, loss: 0.04, accuracy: 99.03\n",
      "train epoch: 7, loss: 0.0165, accuracy: 99.50\n",
      "test epoch: 7, loss: 0.04, accuracy: 99.03\n",
      "train epoch: 8, loss: 0.0149, accuracy: 99.53\n",
      "test epoch: 8, loss: 0.04, accuracy: 98.82\n",
      "train epoch: 9, loss: 0.0106, accuracy: 99.67\n",
      "test epoch: 9, loss: 0.04, accuracy: 99.05\n",
      "train epoch: 10, loss: 0.0082, accuracy: 99.73\n",
      "test epoch: 10, loss: 0.06, accuracy: 98.64\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    state = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "    test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "    print(f'test epoch: {epoch}, loss: {test_loss:.2f}, accuracy: {100 * test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他\n",
    "- [OOM について](https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html)\n",
    "- [PRNGKey について](https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html)\n",
    "- [pytree について](https://jax.readthedocs.io/en/latest/jax-101/05.1-pytrees.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0274f19de90e75d0030915c9204ef0c9b6e3c2e4dc43f915a5e0d173d93093ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
